{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesta fase, irei iniciar a etapa de experimentação, onde irei testar uma série \n",
    "de modelos de classificação para encontrar o que melhor se adequa ao problema.\n",
    "Vale ressaltar que apenas algumas colunas serão utilizadas para a criação dos\n",
    "modelos, pois algumas só são obtidas ao fim do processo do SISU, como é o caso\n",
    "da coluna \"NOTA_CORTE\" e \"CLASSIFICACAO\". Outras colunas como códigos das IES\n",
    "e cursos também não serão utilizadas, pois não são relevantes para o problema.\n",
    "Ao final, além do modelo, um conjunto de dados no formato .db será gerado para\n",
    "ser consumido pelo app final. Segue abaixo as colunas que serão utilizadas:\n",
    "\n",
    "- Modelo: IES, UF_CAMPUS, MUNICIPIO_CAMPUS, NOME_CURSO, GRAU, TURNO, \n",
    "TIPO_MOD_CONCORRENCIA, QT_VAGAS_CONCORRENCIA, PERCENTUAL_BONUS, PESO_L, PESO_CH,\n",
    "PESO_CN, PESO_M, PESO_R, NOTA_MINIMA_L, NOTA_MINIMA_CH, NOTA_MINIMA_CN, \n",
    "NOTA_MINIMA_M, NOTA_MINIMA_R, MEDIA_MINIMA, OPCAO, NOTA_L, NOTA_CH, NOTA_CN, \n",
    "NOTA_M, NOTA_R, NOTA_L_COM_PESO, NOTA_CH_COM_PESO, NOTA_CN_COM_PESO, \n",
    "NOTA_M_COM_PESO, NOTA_R_COM_PESO, NOTA_CANDIDATO e APROVADO.\n",
    "\n",
    "Vale ressaltar que parte das informações que serão utilizadas no Web App serão \n",
    "buscadas nos dados do SISU, como é o caso da QT_VAGAS_CONCORRENCIA, que é um \n",
    "valor que a universidade define para cada curso e não o usuário. Outras serão \n",
    "calculadas manualmente, como no caso das notas com peso.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "import category_encoders as ce\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, PowerTransformer, OneHotEncoder, PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import log_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lendo os dados\n",
    "dados_sisu = pd.read_parquet('../data/processed/dados_transformados.parquet/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo as colunas que serão utilizadas para treinar o modelo\n",
    "colunas_para_buscar = ['IES', 'UF_CAMPUS', 'MUNICIPIO_CAMPUS', 'NOME_CURSO', \n",
    "                       'GRAU', 'TURNO', 'TIPO_MOD_CONCORRENCIA', \n",
    "                       'QT_VAGAS_CONCORRENCIA', 'PERCENTUAL_BONUS', 'PESO_L', \n",
    "                       'PESO_CH', 'PESO_CN', 'PESO_M', 'PESO_R', \n",
    "                       'NOTA_MINIMA_L', 'NOTA_MINIMA_CH', 'NOTA_MINIMA_CN', \n",
    "                       'NOTA_MINIMA_M', 'NOTA_MINIMA_R', 'MEDIA_MINIMA', \n",
    "                       'OPCAO', 'NOTA_L', 'NOTA_CH', 'NOTA_CN', 'NOTA_M', \n",
    "                       'NOTA_R', 'NOTA_L_COM_PESO', 'NOTA_CH_COM_PESO', \n",
    "                       'NOTA_CN_COM_PESO', 'NOTA_M_COM_PESO', 'NOTA_R_COM_PESO',\n",
    "                       'NOTA_CANDIDATO', 'APROVADO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrando as colunas\n",
    "dados_sisu = dados_sisu[colunas_para_buscar]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "APROVADO\n",
       "N    0.898245\n",
       "S    0.101755\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificando o balanceamento da variável alvo\n",
    "dados_sisu['APROVADO'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/11/30 17:10:49 INFO mlflow.tracking.fluent: Experiment with name 'Comparando modelos' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='/home/daniel/Documents/sisu_analysis/notebooks/../mlruns/121856067394284381', creation_time=1701375049985, experiment_id='121856067394284381', last_update_time=1701375049985, lifecycle_stage='active', name='Comparando modelos', tags={}>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define o local para salvar os exoerimentos\n",
    "mlflow.set_tracking_uri('../mlruns')\n",
    "\n",
    "# Criando/acessando o experimento\n",
    "mlflow.set_experiment('Comparando modelos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividindo os dados em variaveis explicativas e variavel alvo\n",
    "x = dados_sisu.drop(columns=['APROVADO'])\n",
    "y = dados_sisu['APROVADO'].map({'S': 1, 'N': 0})\n",
    "y\n",
    "\n",
    "# Dividindo os dados em treino e teste\n",
    "x_treino, x_teste, y_treino, y_teste = train_test_split(x, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Dividindo os dados em teste e dev\n",
    "x_teste, x_dev, y_teste, y_dev = train_test_split(x_teste, y_teste, test_size=0.5, random_state=42, stratify=y_teste)\n",
    "\n",
    "# Dividindo os dados em dev e calibração\n",
    "x_dev, x_calibracao, y_dev, y_calibracao = train_test_split(x_dev, y_dev, test_size=0.5, random_state=42, stratify=y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividindo as colunas por tipo\n",
    "high_dim_cols = ['MUNICIPIO_CAMPUS', 'IES', 'NOME_CURSO']\n",
    "num_cols = x_treino.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "cat_cols = x_treino.select_dtypes(include=['object']).columns.tolist()\n",
    "cat_cols = [col for col in cat_cols if col not in high_dim_cols]\n",
    "\n",
    "# Criando o kfolds\n",
    "kfolds = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Criando um scaler padrão\n",
    "scale = y_treino.value_counts()[0] / y_treino.value_counts()[1] \n",
    "\n",
    "# Criando dicionário com os modelos\n",
    "dict_models_scale_sensitive = {\"LR\": LogisticRegression(random_state=200,\n",
    "                                                        class_weight='balanced')}\n",
    "\n",
    "dict_models_tree_based = {\"LGBM\": LGBMClassifier(is_unbalance=True,\n",
    "                                                 random_state=200),\n",
    "                          \"XGB\": XGBClassifier(scale_pos_weight=scale,\n",
    "                                               random_state=200),\n",
    "                          \"CTBC\": CatBoostClassifier(auto_class_weights='Balanced',\n",
    "                                                     random_state=200),\n",
    "                          \"DT\": DecisionTreeClassifier(class_weight='balanced',\n",
    "                                                       random_state=200),\n",
    "                          \"RF\": RandomForestClassifier(class_weight='balanced',\n",
    "                                                       random_state=200)}\n",
    "\n",
    "# Criando dicionário com os encoders\n",
    "dict_encoders = {\"OHE\": OneHotEncoder(drop='first'),\n",
    "                 \"TE\": ce.TargetEncoder(),\n",
    "                 \"ME\": ce.MEstimateEncoder(),\n",
    "                 \"WOE\": ce.WOEEncoder(),\n",
    "                 \"CE\": ce.CatBoostEncoder(),\n",
    "                 \"GE\":ce.GrayEncoder()}\n",
    "\n",
    "dict_scalers = {\"SS\": StandardScaler()}\n",
    "\n",
    "# Criando dicionário com os transformers\n",
    "dict_transformers = {\"PT\": PowerTransformer(),\n",
    "                     \"PF\": PolynomialFeatures()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mO Kernel falhou ao executar o código na célula atual ou em uma célula anterior. Examine o código nas células para identificar uma possível causa da falha. Clique <a href=\"https://aka.ms/vscodeJupyterKernelCrash\">aqui</a> para obter mais informações. Consulte o <a href='command:jupyter.viewOutput'>log</a> do Jupyter para obter mais detalhes."
     ]
    }
   ],
   "source": [
    "# Iniciando os experimentos sem transformers\n",
    "for tag, model in dict_models_scale_sensitive.items():\n",
    "    for tag_encoder, encoder in dict_encoders.items():\n",
    "        for tag_scaler, scaler in dict_scalers.items():\n",
    "            \n",
    "            # Gerando a tag de identificação do modelo\n",
    "            nome_modelo = f'{tag}_{tag_encoder}_{tag_scaler}'\n",
    "            \n",
    "            with mlflow.start_run(run_name=nome_modelo):\n",
    "                 \n",
    "                 # Criando os pipeline com os transformers\n",
    "                 pipe_cat = Pipeline([('encoder', encoder)])\n",
    "                 pipe_high_dim = Pipeline([('encoder', ce.CountEncoder())])\n",
    "                 pipe_num = Pipeline([('scaler', scaler)])\n",
    "                 \n",
    "                 # Criando o transformador\n",
    "                 transformer = ColumnTransformer([('cat', pipe_cat, cat_cols),\n",
    "                                                 ('num', pipe_num, num_cols),\n",
    "                                                 ('high_dim', pipe_high_dim, high_dim_cols)])\n",
    "                 \n",
    "                 # Criando o pipeline final\n",
    "                 pipe = Pipeline([('transformer', transformer),\n",
    "                                 ('model', model)])\n",
    "                 \n",
    "                 # Executando o cross validation\n",
    "                 cross_val_scores = cross_val_score(pipe, x_treino, y_treino, cv=kfolds, scoring='neg_log_loss')\n",
    "                 \n",
    "                 # Calculando a média das métricas\n",
    "                 mean_score = cross_val_scores.mean()           \n",
    "                 \n",
    "                 # Salvando a métrica da folder 1\n",
    "                 mlflow.log_metric('log_loss_fold_1', cross_val_scores[0])\n",
    "                 \n",
    "                 # Salvando a métrica da folder 2\n",
    "                 mlflow.log_metric('log_loss_fold_2', cross_val_scores[1])\n",
    "                \n",
    "                 # Salvando a métrica da folder 3\n",
    "                 mlflow.log_metric('log_loss_fold_3', cross_val_scores[2])\n",
    "                \n",
    "                 # Salvando a métrica da folder 4\n",
    "                 mlflow.log_metric('log_loss_fold_4', cross_val_scores[3])\n",
    "                \n",
    "                 # Salvando a métrica da folder 5\n",
    "                 mlflow.log_metric('log_loss_fold_5', cross_val_scores[4])\n",
    "                 \n",
    "                 # Salvando as métricas\n",
    "                 mlflow.log_metric('log_loss_mean', mean_score)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
