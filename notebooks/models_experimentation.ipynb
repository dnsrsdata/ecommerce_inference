{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesta fase, irei iniciar a etapa de experimentação, onde irei testar uma série \n",
    "de modelos de classificação para encontrar o que melhor se adequa ao problema.\n",
    "Vale ressaltar que apenas algumas colunas serão utilizadas para a criação dos\n",
    "modelos, pois algumas só são obtidas ao fim do processo do SISU, como é o caso\n",
    "da coluna \"NOTA_CORTE\" e \"CLASSIFICACAO\". Outras colunas como códigos das IES\n",
    "e cursos também não serão utilizadas, pois não são relevantes para o problema.\n",
    "Ao final, além do modelo, um conjunto de dados no formato .db será gerado para\n",
    "ser consumido pelo app final. Segue abaixo as colunas que serão utilizadas:\n",
    "\n",
    "- Modelo: IES, UF_CAMPUS, MUNICIPIO_CAMPUS, NOME_CURSO, GRAU, TURNO, \n",
    "TIPO_MOD_CONCORRENCIA, QT_VAGAS_CONCORRENCIA, PERCENTUAL_BONUS, PESO_L, PESO_CH,\n",
    "PESO_CN, PESO_M, PESO_R, NOTA_MINIMA_L, NOTA_MINIMA_CH, NOTA_MINIMA_CN, \n",
    "NOTA_MINIMA_M, NOTA_MINIMA_R, MEDIA_MINIMA, OPCAO, NOTA_L, NOTA_CH, NOTA_CN, \n",
    "NOTA_M, NOTA_R, NOTA_L_COM_PESO, NOTA_CH_COM_PESO, NOTA_CN_COM_PESO, \n",
    "NOTA_M_COM_PESO, NOTA_R_COM_PESO, NOTA_CANDIDATO e APROVADO.\n",
    "\n",
    "Vale ressaltar que parte das informações que serão utilizadas no Web App serão \n",
    "buscadas nos dados do SISU, como é o caso da QT_VAGAS_CONCORRENCIA, que é um \n",
    "valor que a universidade define para cada curso e não o usuário. Outras serão \n",
    "calculadas manualmente, como no caso das notas com peso.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import joblib\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import category_encoders as ce\n",
    "\n",
    "# Preprocessing & Models\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PowerTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "\n",
    "# Métricas\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lendo os dados\n",
    "dados_sisu_full = pd.read_parquet('../data/processed/dados_transformados.parquet/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo as colunas que serão utilizadas para treinar o modelo\n",
    "colunas_para_buscar = ['IES', 'UF_CAMPUS', 'MUNICIPIO_CAMPUS', 'NOME_CURSO', \n",
    "                       'GRAU', 'TURNO', 'TIPO_MOD_CONCORRENCIA', \n",
    "                       'QT_VAGAS_CONCORRENCIA', 'PERCENTUAL_BONUS', 'PESO_L', \n",
    "                       'PESO_CH', 'PESO_CN', 'PESO_M', 'PESO_R', \n",
    "                       'NOTA_MINIMA_L', 'NOTA_MINIMA_CH', 'NOTA_MINIMA_CN', \n",
    "                       'NOTA_MINIMA_M', 'NOTA_MINIMA_R', 'MEDIA_MINIMA', \n",
    "                       'OPCAO', 'NOTA_L', 'NOTA_CH', 'NOTA_CN', 'NOTA_M', \n",
    "                       'NOTA_R', 'NOTA_L_COM_PESO', 'NOTA_CH_COM_PESO', \n",
    "                       'NOTA_CN_COM_PESO', 'NOTA_M_COM_PESO', 'NOTA_R_COM_PESO',\n",
    "                       'NOTA_CANDIDATO', 'APROVADO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrando as colunas\n",
    "dados_sisu = dados_sisu_full[colunas_para_buscar]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N    0.898245\n",
       "S    0.101755\n",
       "Name: APROVADO, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificando o balanceamento da variável alvo\n",
    "dados_sisu['APROVADO'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='/home/daniel/Documents/sisu_analysis/notebooks/../mlruns/980913714926035010', creation_time=1702469991297, experiment_id='980913714926035010', last_update_time=1702469991297, lifecycle_stage='active', name='Comparando modelos', tags={}>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define o local para salvar os experimentos\n",
    "mlflow.set_tracking_uri('../mlruns')\n",
    "\n",
    "# Criando/acessando o experimento\n",
    "mlflow.set_experiment('Comparando modelos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividindo os dados em variaveis explicativas e variavel alvo\n",
    "x = dados_sisu.drop(columns=['APROVADO'])\n",
    "y = dados_sisu['APROVADO'].map({'S': 1, 'N': 0})\n",
    "\n",
    "# Dividindo os dados em treino e teste\n",
    "x_treino, x_teste, y_treino, y_teste = train_test_split(x, y, test_size=0.45, random_state=42, stratify=y)\n",
    "\n",
    "# Dividindo os dados em teste e dev\n",
    "x_teste, x_dev, y_teste, y_dev = train_test_split(x_teste, y_teste, test_size=0.5, random_state=42, stratify=y_teste)\n",
    "\n",
    "# Dividindo os dados em dev e calibração\n",
    "x_dev, x_calib, y_dev, y_calib = train_test_split(x_dev, y_dev, test_size=0.5, random_state=42, stratify=y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando um scaler padrão\n",
    "scale = y_treino.value_counts()[0] / y_treino.value_counts()[1] \n",
    "\n",
    "# Criando dicionário com os modelos\n",
    "dict_models_scale_sensitive_cw = {\"LR\": LogisticRegression(random_state=200, \n",
    "                                                           class_weight='balanced')}\n",
    "\n",
    "dict_models_scale_sensitive_no_cw = {\"LR\": LogisticRegression(random_state=200)}\n",
    "\n",
    "dict_models_tree_based_cw = {\"LGBM\": LGBMClassifier(is_unbalance=True,\n",
    "                                                 random_state=200),\n",
    "                          \"XGB\": XGBClassifier(scale_pos_weight=scale,\n",
    "                                               random_state=200),\n",
    "                          \"CTBC\": CatBoostClassifier(auto_class_weights='Balanced',\n",
    "                                                     random_state=200)}\n",
    "\n",
    "dict_models_tree_based_no_cw = {\"LGBM\": LGBMClassifier(random_state=200),\n",
    "                          \"XGB\": XGBClassifier(random_state=200),\n",
    "                          \"CTBC\": CatBoostClassifier(random_state=200)}\n",
    "\n",
    "# Criando dicionário com os encoders\n",
    "dict_encoders = {\"OHE\": OneHotEncoder(drop='first'),\n",
    "                 \"TE\": ce.TargetEncoder(),\n",
    "                 \"BE\": ce.BinaryEncoder(),\n",
    "                 \"ME\": ce.MEstimateEncoder(),\n",
    "                 \"WOE\": ce.WOEEncoder(),\n",
    "                 \"CE\": ce.CatBoostEncoder(),\n",
    "                 \"GE\":ce.GrayEncoder()}\n",
    "\n",
    "dict_scalers = {\"SS\": StandardScaler()}\n",
    "\n",
    "# Criando dicionário com os transformers\n",
    "dict_transformers = {\"PT\": PowerTransformer()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo as folds\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=200)\n",
    "\n",
    "# Retornando os nomes das colunas com mais de 25 valores únicos\n",
    "cat_cols = x_treino.select_dtypes(include='object').columns\n",
    "high_dim_cols = cat_cols[x_treino[cat_cols].nunique() > 25]\n",
    "\n",
    "# Retornando os nomes das colunas com menos de 25 valores únicos\n",
    "cat_cols = [col for col in cat_cols if col not in high_dim_cols]\n",
    "\n",
    "# Buscando as colunas numéricas\n",
    "num_cols = x_treino.select_dtypes(include=['int', 'float']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Iniciando os experimentos sem transformers e com class_weight\n",
    "#for tag, model in dict_models_scale_sensitive_cw.items():\n",
    "#    for tag_encoder, encoder in dict_encoders.items():\n",
    "#        for tag_scaler, scaler in dict_scalers.items():\n",
    "#            \n",
    "#            # Gerando a tag de identificação do modelo\n",
    "#            nome_modelo = f'{tag}_CW_{tag_encoder}_{tag_scaler}'\n",
    "#            \n",
    "#            with mlflow.start_run(run_name=nome_modelo):\n",
    "#                 \n",
    "#                 # Criando os pipeline com os transformers\n",
    "#                 pipe_cat = Pipeline([('encoder', encoder)])\n",
    "#                 pipe_high_dim = Pipeline([('encoder', ce.CountEncoder())])\n",
    "#                 pipe_num = Pipeline([('scaler', scaler)])\n",
    "#                 \n",
    "#                 # Criando o transformador\n",
    "#                 transformer = ColumnTransformer([('cat', pipe_cat, cat_cols),\n",
    "#                                                 ('num', pipe_num, num_cols),\n",
    "#                                                 ('high_dim', pipe_high_dim, high_dim_cols)])\n",
    "#                 \n",
    "#                 # Criando o pipeline final\n",
    "#                 pipe = Pipeline([('transformer', transformer),\n",
    "#                                 ('model', model)])\n",
    "#                 \n",
    "#                 # Executando o cross validation\n",
    "#                 cross_val_scores = cross_val_score(pipe, x_treino, y_treino, cv=kf, scoring='neg_log_loss')\n",
    "#                 \n",
    "#                 # Calculando a média das métricas\n",
    "#                 mean_score = cross_val_scores.mean()           \n",
    "#                 \n",
    "#                 # Salvando a métrica da folder 1\n",
    "#                 mlflow.log_metric('log_loss_fold_1', cross_val_scores[0])\n",
    "#                 \n",
    "#                 # Salvando a métrica da folder 2\n",
    "#                 mlflow.log_metric('log_loss_fold_2', cross_val_scores[1])\n",
    "#                \n",
    "#                 # Salvando a métrica da folder 3\n",
    "#                 mlflow.log_metric('log_loss_fold_3', cross_val_scores[2])\n",
    "#                \n",
    "#                 # Salvando a métrica da folder 4\n",
    "#                 mlflow.log_metric('log_loss_fold_4', cross_val_scores[3])\n",
    "#                \n",
    "#                 # Salvando a métrica da folder 5\n",
    "#                 mlflow.log_metric('log_loss_fold_5', cross_val_scores[4])\n",
    "#                 \n",
    "#                 # Salvando as métricas\n",
    "#                 mlflow.log_metric('log_loss_mean', mean_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Iniciando os experimentos sem transformers e sem class_weight\n",
    "#for tag, model in dict_models_scale_sensitive_no_cw.items():\n",
    "#    for tag_encoder, encoder in dict_encoders.items():\n",
    "#        for tag_scaler, scaler in dict_scalers.items():\n",
    "#            \n",
    "#            # Gerando a tag de identificação do modelo\n",
    "#            nome_modelo = f'{tag}_NO_CW_{tag_encoder}_{tag_scaler}'\n",
    "#            \n",
    "#            with mlflow.start_run(run_name=nome_modelo):\n",
    "#                 \n",
    "#                 # Criando os pipeline com os transformers\n",
    "#                 pipe_cat = Pipeline([('encoder', encoder)])\n",
    "#                 pipe_high_dim = Pipeline([('encoder', ce.CountEncoder())])\n",
    "#                 pipe_num = Pipeline([('scaler', scaler)])\n",
    "#                 \n",
    "#                 # Criando o transformador\n",
    "#                 transformer = ColumnTransformer([('cat', pipe_cat, cat_cols),\n",
    "#                                                 ('num', pipe_num, num_cols),\n",
    "#                                                 ('high_dim', pipe_high_dim, high_dim_cols)])\n",
    "#                 \n",
    "#                 # Criando o pipeline final\n",
    "#                 pipe = Pipeline([('transformer', transformer),\n",
    "#                                 ('model', model)])\n",
    "#                 \n",
    "#                 # Executando o cross validation\n",
    "#                 cross_val_scores = cross_val_score(pipe, x_treino, y_treino, cv=kf, scoring='neg_log_loss')\n",
    "#                 \n",
    "#                 # Calculando a média das métricas\n",
    "#                 mean_score = cross_val_scores.mean()           \n",
    "#                 \n",
    "#                 # Salvando a métrica da folder 1\n",
    "#                 mlflow.log_metric('log_loss_fold_1', cross_val_scores[0])\n",
    "#                 \n",
    "#                 # Salvando a métrica da folder 2\n",
    "#                 mlflow.log_metric('log_loss_fold_2', cross_val_scores[1])\n",
    "#                \n",
    "#                 # Salvando a métrica da folder 3\n",
    "#                 mlflow.log_metric('log_loss_fold_3', cross_val_scores[2])\n",
    "#                \n",
    "#                 # Salvando a métrica da folder 4\n",
    "#                 mlflow.log_metric('log_loss_fold_4', cross_val_scores[3])\n",
    "#                \n",
    "#                 # Salvando a métrica da folder 5\n",
    "#                 mlflow.log_metric('log_loss_fold_5', cross_val_scores[4])\n",
    "#                 \n",
    "#                 # Salvando as métricas\n",
    "#                 mlflow.log_metric('log_loss_mean', mean_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Iniciando os experimentos com transformers e sem class_weight\n",
    "#for tag, model in dict_models_scale_sensitive_no_cw.items():\n",
    "#    for tag_encoder, encoder in dict_encoders.items():\n",
    "#        for tag_scaler, scaler in dict_scalers.items():\n",
    "#            for tag_transformer, transformer in dict_transformers.items():\n",
    "#            \n",
    "#                # Gerando a tag de identificação do modelo\n",
    "#                nome_modelo = f'{tag}_NO_CW_{tag_encoder}_{tag_scaler}_{tag_transformer}'\n",
    "#\n",
    "#                with mlflow.start_run(run_name=nome_modelo):\n",
    "#\n",
    "#                     # Criando os pipeline com os transformers\n",
    "#                     pipe_cat = Pipeline([('encoder', encoder)])\n",
    "#                     pipe_high_dim = Pipeline([('encoder', ce.CountEncoder())])\n",
    "#                     pipe_num = Pipeline([('scaler', scaler),\n",
    "#                                          ('transformer', transformer)])\n",
    "#\n",
    "#                     # Criando o transformador\n",
    "#                     transformer = ColumnTransformer([('cat', pipe_cat, cat_cols),\n",
    "#                                                     ('num', pipe_num, num_cols),\n",
    "#                                                     ('high_dim', pipe_high_dim, high_dim_cols)])\n",
    "#\n",
    "#                     # Criando o pipeline final\n",
    "#                     pipe = Pipeline([('transformer', transformer),\n",
    "#                                     ('model', model)])\n",
    "#\n",
    "#                     # Executando o cross validation\n",
    "#                     cross_val_scores = cross_val_score(pipe, x_treino, y_treino, cv=kf, scoring='neg_log_loss')\n",
    "#\n",
    "#                     # Calculando a média das métricas\n",
    "#                     mean_score = cross_val_scores.mean()         \n",
    "#\n",
    "#                     # Salvando a métrica da folder 1\n",
    "#                     mlflow.log_metric('log_loss_fold_1', cross_val_scores[0])\n",
    "#\n",
    "#                     # Salvando a métrica da folder 2\n",
    "#                     mlflow.log_metric('log_loss_fold_2', cross_val_scores[1])\n",
    "#\n",
    "#                     # Salvando a métrica da folder 3\n",
    "#                     mlflow.log_metric('log_loss_fold_3', cross_val_scores[2])\n",
    "#\n",
    "#                     # Salvando a métrica da folder 4\n",
    "#                     mlflow.log_metric('log_loss_fold_4', cross_val_scores[3])\n",
    "#\n",
    "#                     # Salvando a métrica da folder 5\n",
    "#                     mlflow.log_metric('log_loss_fold_5', cross_val_scores[4])\n",
    "#\n",
    "#                     # Salvando as métricas\n",
    "#                     mlflow.log_metric('log_loss_mean', mean_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Iniciando os experimentos com transformers e com class_weight\n",
    "#for tag, model in dict_models_scale_sensitive_cw.items():\n",
    "#    for tag_encoder, encoder in dict_encoders.items():\n",
    "#        for tag_scaler, scaler in dict_scalers.items():\n",
    "#            for tag_transformer, transformer in dict_transformers.items():\n",
    "#            \n",
    "#                # Gerando a tag de identificação do modelo\n",
    "#                nome_modelo = f'{tag}_CW_{tag_encoder}_{tag_scaler}_{tag_transformer}'\n",
    "#\n",
    "#                with mlflow.start_run(run_name=nome_modelo):\n",
    "#\n",
    "#                     # Criando os pipeline com os transformers\n",
    "#                     pipe_cat = Pipeline([('encoder', encoder)])\n",
    "#                     pipe_high_dim = Pipeline([('encoder', ce.CountEncoder())])\n",
    "#                     pipe_num = Pipeline([('scaler', scaler),\n",
    "#                                          ('transformer', transformer)])\n",
    "#\n",
    "#                     # Criando o transformador\n",
    "#                     transformer = ColumnTransformer([('cat', pipe_cat, cat_cols),\n",
    "#                                                     ('num', pipe_num, num_cols),\n",
    "#                                                     ('high_dim', pipe_high_dim, high_dim_cols)])\n",
    "#\n",
    "#                     # Criando o pipeline final\n",
    "#                     pipe = Pipeline([('transformer', transformer),\n",
    "#                                     ('model', model)])\n",
    "#\n",
    "#                     # Executando o cross validation\n",
    "#                     cross_val_scores = cross_val_score(pipe, x_treino, y_treino, cv=kf, scoring='neg_log_loss')\n",
    "#\n",
    "#                     # Calculando a média das métricas\n",
    "#                     mean_score = cross_val_scores.mean()         \n",
    "#\n",
    "#                     # Salvando a métrica da folder 1\n",
    "#                     mlflow.log_metric('log_loss_fold_1', cross_val_scores[0])\n",
    "#\n",
    "#                     # Salvando a métrica da folder 2\n",
    "#                     mlflow.log_metric('log_loss_fold_2', cross_val_scores[1])\n",
    "#\n",
    "#                     # Salvando a métrica da folder 3\n",
    "#                     mlflow.log_metric('log_loss_fold_3', cross_val_scores[2])\n",
    "#\n",
    "#                     # Salvando a métrica da folder 4\n",
    "#                     mlflow.log_metric('log_loss_fold_4', cross_val_scores[3])\n",
    "#\n",
    "#                     # Salvando a métrica da folder 5\n",
    "#                     mlflow.log_metric('log_loss_fold_5', cross_val_scores[4])\n",
    "#\n",
    "#                     # Salvando as métricas\n",
    "#                     mlflow.log_metric('log_loss_mean', mean_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Iniciando os experimentos sem transformers e com class_weight\n",
    "#for tag, model in dict_models_tree_based_cw.items():\n",
    "#    for tag_encoder, encoder in dict_encoders.items():\n",
    "#            \n",
    "#            # Gerando a tag de identificação do modelo\n",
    "#            nome_modelo = f'{tag}_CW_{tag_encoder}'\n",
    "#            \n",
    "#            with mlflow.start_run(run_name=nome_modelo):\n",
    "#                 \n",
    "#                 # Criando os pipeline com os transformers\n",
    "#                 pipe_cat = Pipeline([('encoder', encoder)])\n",
    "#                 pipe_high_dim = Pipeline([('encoder', ce.CountEncoder())])\n",
    "#                 \n",
    "#                 # Criando o transformador\n",
    "#                 transformer = ColumnTransformer([('cat', pipe_cat, cat_cols),\n",
    "#                                                 ('high_dim', pipe_high_dim, high_dim_cols)])\n",
    "#                 \n",
    "#                 # Criando o pipeline final\n",
    "#                 pipe = Pipeline([('transformer', transformer),\n",
    "#                                 ('model', model)])\n",
    "#                 \n",
    "#                 # Executando o cross validation\n",
    "#                 cross_val_scores = cross_val_score(pipe, x_treino, y_treino, cv=kf, scoring='neg_log_loss')\n",
    "#                 \n",
    "#                 # Calculando a média das métricas\n",
    "#                 mean_score = cross_val_scores.mean()         \n",
    "#                 \n",
    "#                 # Salvando a métrica da folder 1\n",
    "#                 mlflow.log_metric('log_loss_fold_1', cross_val_scores[0])\n",
    "#                 \n",
    "#                 # Salvando a métrica da folder 2\n",
    "#                 mlflow.log_metric('log_loss_fold_2', cross_val_scores[1])\n",
    "#                \n",
    "#                 # Salvando a métrica da folder 3\n",
    "#                 mlflow.log_metric('log_loss_fold_3', cross_val_scores[2])\n",
    "#                \n",
    "#                 # Salvando a métrica da folder 4\n",
    "#                 mlflow.log_metric('log_loss_fold_4', cross_val_scores[3])\n",
    "#                \n",
    "#                 # Salvando a métrica da folder 5\n",
    "#                 mlflow.log_metric('log_loss_fold_5', cross_val_scores[4])\n",
    "#                 \n",
    "#                 # Salvando as métricas\n",
    "#                 mlflow.log_metric('log_loss_mean', mean_score)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Iniciando os experimentos sem transformers e sem class_weight\n",
    "#for tag, model in dict_models_tree_based_no_cw.items():\n",
    "#    for tag_encoder, encoder in dict_encoders.items():\n",
    "#            \n",
    "#            # Gerando a tag de identificação do modelo\n",
    "#            nome_modelo = f'{tag}_NO_CW_{tag_encoder}'\n",
    "#            \n",
    "#            with mlflow.start_run(run_name=nome_modelo):\n",
    "#                 \n",
    "#                 # Criando os pipeline com os transformers\n",
    "#                 pipe_cat = Pipeline([('encoder', encoder)])\n",
    "#                 pipe_high_dim = Pipeline([('encoder', ce.CountEncoder())])\n",
    "#                 \n",
    "#                 # Criando o transformador\n",
    "#                 transformer = ColumnTransformer([('cat', pipe_cat, cat_cols),\n",
    "#                                                 ('high_dim', pipe_high_dim, high_dim_cols)])\n",
    "#                 \n",
    "#                 # Criando o pipeline final\n",
    "#                 pipe = Pipeline([('transformer', transformer),\n",
    "#                                 ('model', model)])\n",
    "#                 \n",
    "#                 # Executando o cross validation\n",
    "#                 cross_val_scores = cross_val_score(pipe, x_treino, y_treino, cv=kf, scoring='neg_log_loss')\n",
    "#                 \n",
    "#                 # Calculando a média das métricas\n",
    "#                 mean_score = cross_val_scores.mean()         \n",
    "#                 \n",
    "#                 # Salvando a métrica da folder 1\n",
    "#                 mlflow.log_metric('log_loss_fold_1', cross_val_scores[0])\n",
    "#                 \n",
    "#                 # Salvando a métrica da folder 2\n",
    "#                 mlflow.log_metric('log_loss_fold_2', cross_val_scores[1])\n",
    "#                \n",
    "#                 # Salvando a métrica da folder 3\n",
    "#                 mlflow.log_metric('log_loss_fold_3', cross_val_scores[2])\n",
    "#                \n",
    "#                 # Salvando a métrica da folder 4\n",
    "#                 mlflow.log_metric('log_loss_fold_4', cross_val_scores[3])\n",
    "#                \n",
    "#                 # Salvando a métrica da folder 5\n",
    "#                 mlflow.log_metric('log_loss_fold_5', cross_val_scores[4])\n",
    "#                 \n",
    "#                 # Salvando as métricas\n",
    "#                 mlflow.log_metric('log_loss_mean', mean_score)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Especificando as colunas para retornar\n",
    "colunas = ['tags.mlflow.runName', 'metrics.log_loss_mean']\n",
    "\n",
    "# Buscando os melhores modelos\n",
    "mlflow.search_runs(order_by=['metrics.log_loss_mean DESC'], max_results=15)[colunas]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os modelos sem Class_Weight foram os melhores classificadores. Dentre os \n",
    "melhores, é perceptível a baixa diferença entre os modelos. Dado a isso, iremos\n",
    "selecionar os dois melhores modelos para a tunagem de hiperparâmetros, que são \n",
    "a Regressão Logística e o CatBoost. Os dois serão testados em um ensemble.\n",
    "\n",
    "Como a natureza da solução exige respostas rápidas, a Regressão Logística terá \n",
    "preferência sobre o CatBoost e o Ensemble de ambos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressão Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Criando função para tunar o modelo\n",
    "#def objective(trial):\n",
    "#\n",
    "#    params = {\n",
    "#        'C': trial.suggest_float('C', 1e-4, 1e+4, log=True),\n",
    "#        'penalty': trial.suggest_categorical('penalty', [None, 'l2']),\n",
    "#        'solver': trial.suggest_categorical('solver', ['lbfgs', 'saga', 'newton-cholesky']),\n",
    "#        'max_iter': trial.suggest_int('max_iter', 50, 1000),\n",
    "#        'fit_intercept': trial.suggest_categorical('fit_intercept', [True, False]),\n",
    "#        'class_weight': trial.suggest_categorical('class_weight', [None, 'balanced']),\n",
    "#        'random_state': 200\n",
    "#    }\n",
    "#    \n",
    "#    # Criando os pipeline com os transformers\n",
    "#    pipe_cat = Pipeline([('encoder', ce.BinaryEncoder())])\n",
    "#    pipe_high_dim = Pipeline([('encoder', ce.CountEncoder())])\n",
    "#    pipe_num = Pipeline([('scaler', StandardScaler())])\n",
    "#    \n",
    "#    # Criando o transformador\n",
    "#    transformer = ColumnTransformer([('cat', pipe_cat, cat_cols),\n",
    "#                                    ('num', pipe_num, num_cols),\n",
    "#                                    ('high_dim', pipe_high_dim, high_dim_cols)])\n",
    "#    \n",
    "#    # Criando o pipeline final\n",
    "#    pipe = Pipeline([('transformer', transformer),\n",
    "#                    ('model', LogisticRegression(**params))])\n",
    "#\n",
    "#    # Treinando o modelo com os dados de treino\n",
    "#    pipe.fit(x_treino, y_treino)\n",
    "#   \n",
    "#    logloss = log_loss(y_dev, pipe.predict_proba(x_dev))\n",
    "#    \n",
    "#    return logloss\n",
    "#\n",
    "## Criando o estudo de otimização\n",
    "#study = optuna.create_study(direction = 'minimize')\n",
    "#study.optimize(objective, n_trials = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# O resultado do hiperparâmetro otimizado pode ser diferente a cada execução.\n",
    "# Resultado atingido: 0.23\n",
    "\n",
    "# Checando os melhores parâmetros\n",
    "#study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;transformer&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;cat&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;encoder&#x27;,\n",
       "                                                                   BinaryEncoder())]),\n",
       "                                                  [4, 5, 6, 9, 10, 11, 12, 13,\n",
       "                                                   20]),\n",
       "                                                 (&#x27;num&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;scaler&#x27;,\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  [7, 8, 14, 15, 16, 17, 18, 19,\n",
       "                                                   21, 22, 23, 24, 25, 26, 27,\n",
       "                                                   28, 29, 30, 31]),\n",
       "                                                 (&#x27;high_dim&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;encoder&#x27;,\n",
       "                                                                   CountEncoder(combine_min_nan_groups=True))]),\n",
       "                                                  [0, 1, 2, 3])])),\n",
       "                (&#x27;model&#x27;,\n",
       "                 LogisticRegression(C=0.08250109742237544, fit_intercept=False,\n",
       "                                    max_iter=244, random_state=200,\n",
       "                                    solver=&#x27;newton-cholesky&#x27;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;transformer&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;cat&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;encoder&#x27;,\n",
       "                                                                   BinaryEncoder())]),\n",
       "                                                  [4, 5, 6, 9, 10, 11, 12, 13,\n",
       "                                                   20]),\n",
       "                                                 (&#x27;num&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;scaler&#x27;,\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  [7, 8, 14, 15, 16, 17, 18, 19,\n",
       "                                                   21, 22, 23, 24, 25, 26, 27,\n",
       "                                                   28, 29, 30, 31]),\n",
       "                                                 (&#x27;high_dim&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;encoder&#x27;,\n",
       "                                                                   CountEncoder(combine_min_nan_groups=True))]),\n",
       "                                                  [0, 1, 2, 3])])),\n",
       "                (&#x27;model&#x27;,\n",
       "                 LogisticRegression(C=0.08250109742237544, fit_intercept=False,\n",
       "                                    max_iter=244, random_state=200,\n",
       "                                    solver=&#x27;newton-cholesky&#x27;))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">transformer: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;cat&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;encoder&#x27;, BinaryEncoder())]),\n",
       "                                 [4, 5, 6, 9, 10, 11, 12, 13, 20]),\n",
       "                                (&#x27;num&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler())]),\n",
       "                                 [7, 8, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24,\n",
       "                                  25, 26, 27, 28, 29, 30, 31]),\n",
       "                                (&#x27;high_dim&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;encoder&#x27;,\n",
       "                                                  CountEncoder(combine_min_nan_groups=True))]),\n",
       "                                 [0, 1, 2, 3])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cat</label><div class=\"sk-toggleable__content\"><pre>[4, 5, 6, 9, 10, 11, 12, 13, 20]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BinaryEncoder</label><div class=\"sk-toggleable__content\"><pre>BinaryEncoder()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num</label><div class=\"sk-toggleable__content\"><pre>[7, 8, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">high_dim</label><div class=\"sk-toggleable__content\"><pre>[0, 1, 2, 3]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountEncoder</label><div class=\"sk-toggleable__content\"><pre>CountEncoder(combine_min_nan_groups=True)</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.08250109742237544, fit_intercept=False, max_iter=244,\n",
       "                   random_state=200, solver=&#x27;newton-cholesky&#x27;)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('transformer',\n",
       "                 ColumnTransformer(transformers=[('cat',\n",
       "                                                  Pipeline(steps=[('encoder',\n",
       "                                                                   BinaryEncoder())]),\n",
       "                                                  [4, 5, 6, 9, 10, 11, 12, 13,\n",
       "                                                   20]),\n",
       "                                                 ('num',\n",
       "                                                  Pipeline(steps=[('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  [7, 8, 14, 15, 16, 17, 18, 19,\n",
       "                                                   21, 22, 23, 24, 25, 26, 27,\n",
       "                                                   28, 29, 30, 31]),\n",
       "                                                 ('high_dim',\n",
       "                                                  Pipeline(steps=[('encoder',\n",
       "                                                                   CountEncoder(combine_min_nan_groups=True))]),\n",
       "                                                  [0, 1, 2, 3])])),\n",
       "                ('model',\n",
       "                 LogisticRegression(C=0.08250109742237544, fit_intercept=False,\n",
       "                                    max_iter=244, random_state=200,\n",
       "                                    solver='newton-cholesky'))])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criando os pipeline com os transformers\n",
    "pipe_cat = Pipeline([('encoder', ce.BinaryEncoder())])\n",
    "pipe_high_dim = Pipeline([('encoder', ce.CountEncoder())])\n",
    "pipe_num = Pipeline([('scaler', StandardScaler())])\n",
    "\n",
    "# Capturando os indices das colunas\n",
    "cat_cols_index = [x_treino.columns.get_loc(col) for col in cat_cols]\n",
    "num_cols_index = [x_treino.columns.get_loc(col) for col in num_cols]\n",
    "high_dim_cols_index = [x_treino.columns.get_loc(col) for col in high_dim_cols]\n",
    "\n",
    "# Criando o transformador\n",
    "transformer = ColumnTransformer([('cat', pipe_cat, cat_cols_index),\n",
    "                                ('num', pipe_num, num_cols_index),\n",
    "                                ('high_dim', pipe_high_dim, high_dim_cols_index)])\n",
    "\n",
    "# Criando o pipeline final\n",
    "best_lr = Pipeline([('transformer', transformer),\n",
    "                ('model', LogisticRegression(C=0.08250109742237544,\n",
    "                                             penalty='l2',\n",
    "                                             solver='newton-cholesky',\n",
    "                                             max_iter=244,\n",
    "                                             fit_intercept=False,\n",
    "                                             class_weight=None,\n",
    "                                             random_state=200))])\n",
    "\n",
    "best_lr.fit(x_treino.values, y_treino.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Criando função para tunar o modelo\n",
    "#def objective(trial):\n",
    "#\n",
    "#    params = {\n",
    "#        'objective': 'Logloss',\n",
    "#        'eval_metric': 'Logloss',\n",
    "#        'scale_pos_weight': trial.suggest_float('scale_pos_weight', 1, 10),\n",
    "#        'depth': trial.suggest_int('depth', 3, 10),\n",
    "#        'min_child_samples': trial.suggest_int('min_child_samples', 1, 20),\n",
    "#        'subsample': trial.suggest_float('subsample', 0.5, 1),\n",
    "#        'colsample_bylevel': trial.suggest_float('colsample_bylevel', 0.5, 1),\n",
    "#        'reg_lambda': trial.suggest_float('reg_lambda', 1e-3, 10),\n",
    "#        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1),\n",
    "#        'random_state': 200\n",
    "#    }\n",
    "#    \n",
    "#    pipe_cat = Pipeline([('encoder', ce.GrayEncoder())])\n",
    "#    pipe_high_dim = Pipeline([('encoder', ce.CountEncoder())])\n",
    "#\n",
    "#    # Criando o transformador\n",
    "#    transformer = ColumnTransformer([('cat', pipe_cat, cat_cols),\n",
    "#                                    ('high_dim', pipe_high_dim, high_dim_cols)])\n",
    "#\n",
    "#    # Criando o pipeline final\n",
    "#    pipe = Pipeline([('transformer', transformer),\n",
    "#                    ('rf', CatBoostClassifier(**params))])\n",
    "#\n",
    "#    # Treinando o modelo com os dados de treino\n",
    "#    pipe.fit(x_treino, y_treino)\n",
    "#   \n",
    "#    logloss = log_loss(y_dev, pipe.predict_proba(x_dev))\n",
    "#    \n",
    "#    return logloss\n",
    "#\n",
    "## Criando o estudo de otimização\n",
    "#study = optuna.create_study(direction = 'minimize')\n",
    "#study.optimize(objective, n_trials = 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Não foi registrado um aumento significativa com a tunagem, por isso, o modelo\n",
    "será o padrão."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testando e retreianando o modelo com todos os dados\n",
    "\n",
    "Como o Catboost não obteve um aumento significativo com a tunagem, iremos\n",
    "seguir apenas com a Regressão Logística. Além disso, por não necessitar de\n",
    "calibração de probabilidade, essa parte será pulada. Entretando, como os dados \n",
    "para calibração já foram divididos, iremos utiliza-los para avaliação extra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2351030861363363"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Avaliando a melhor Regressão Logística nos dados de teste\n",
    "log_loss(y_teste.values, best_lr.predict_proba(x_teste.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23674439775667952"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Avaliando a melhor Regressão Logística nos dados de calibração\n",
    "log_loss(y_calib.values, best_lr.predict_proba(x_calib.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;transformer&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;cat&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;encoder&#x27;,\n",
       "                                                                   BinaryEncoder())]),\n",
       "                                                  [4, 5, 6, 9, 10, 11, 12, 13,\n",
       "                                                   20]),\n",
       "                                                 (&#x27;num&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;scaler&#x27;,\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  [7, 8, 14, 15, 16, 17, 18, 19,\n",
       "                                                   21, 22, 23, 24, 25, 26, 27,\n",
       "                                                   28, 29, 30, 31]),\n",
       "                                                 (&#x27;high_dim&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;encoder&#x27;,\n",
       "                                                                   CountEncoder(combine_min_nan_groups=True))]),\n",
       "                                                  [0, 1, 2, 3])])),\n",
       "                (&#x27;model&#x27;,\n",
       "                 LogisticRegression(C=0.08250109742237544, fit_intercept=False,\n",
       "                                    max_iter=244, random_state=200,\n",
       "                                    solver=&#x27;newton-cholesky&#x27;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;transformer&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;cat&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;encoder&#x27;,\n",
       "                                                                   BinaryEncoder())]),\n",
       "                                                  [4, 5, 6, 9, 10, 11, 12, 13,\n",
       "                                                   20]),\n",
       "                                                 (&#x27;num&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;scaler&#x27;,\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  [7, 8, 14, 15, 16, 17, 18, 19,\n",
       "                                                   21, 22, 23, 24, 25, 26, 27,\n",
       "                                                   28, 29, 30, 31]),\n",
       "                                                 (&#x27;high_dim&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;encoder&#x27;,\n",
       "                                                                   CountEncoder(combine_min_nan_groups=True))]),\n",
       "                                                  [0, 1, 2, 3])])),\n",
       "                (&#x27;model&#x27;,\n",
       "                 LogisticRegression(C=0.08250109742237544, fit_intercept=False,\n",
       "                                    max_iter=244, random_state=200,\n",
       "                                    solver=&#x27;newton-cholesky&#x27;))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">transformer: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;cat&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;encoder&#x27;, BinaryEncoder())]),\n",
       "                                 [4, 5, 6, 9, 10, 11, 12, 13, 20]),\n",
       "                                (&#x27;num&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler())]),\n",
       "                                 [7, 8, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24,\n",
       "                                  25, 26, 27, 28, 29, 30, 31]),\n",
       "                                (&#x27;high_dim&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;encoder&#x27;,\n",
       "                                                  CountEncoder(combine_min_nan_groups=True))]),\n",
       "                                 [0, 1, 2, 3])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cat</label><div class=\"sk-toggleable__content\"><pre>[4, 5, 6, 9, 10, 11, 12, 13, 20]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BinaryEncoder</label><div class=\"sk-toggleable__content\"><pre>BinaryEncoder()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num</label><div class=\"sk-toggleable__content\"><pre>[7, 8, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" ><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">high_dim</label><div class=\"sk-toggleable__content\"><pre>[0, 1, 2, 3]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" ><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountEncoder</label><div class=\"sk-toggleable__content\"><pre>CountEncoder(combine_min_nan_groups=True)</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-27\" type=\"checkbox\" ><label for=\"sk-estimator-id-27\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.08250109742237544, fit_intercept=False, max_iter=244,\n",
       "                   random_state=200, solver=&#x27;newton-cholesky&#x27;)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('transformer',\n",
       "                 ColumnTransformer(transformers=[('cat',\n",
       "                                                  Pipeline(steps=[('encoder',\n",
       "                                                                   BinaryEncoder())]),\n",
       "                                                  [4, 5, 6, 9, 10, 11, 12, 13,\n",
       "                                                   20]),\n",
       "                                                 ('num',\n",
       "                                                  Pipeline(steps=[('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  [7, 8, 14, 15, 16, 17, 18, 19,\n",
       "                                                   21, 22, 23, 24, 25, 26, 27,\n",
       "                                                   28, 29, 30, 31]),\n",
       "                                                 ('high_dim',\n",
       "                                                  Pipeline(steps=[('encoder',\n",
       "                                                                   CountEncoder(combine_min_nan_groups=True))]),\n",
       "                                                  [0, 1, 2, 3])])),\n",
       "                ('model',\n",
       "                 LogisticRegression(C=0.08250109742237544, fit_intercept=False,\n",
       "                                    max_iter=244, random_state=200,\n",
       "                                    solver='newton-cholesky'))])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retreinando o modelo com todos os dados\n",
    "best_lr.fit(x.values, y.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/best_lr.pkl']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Salvando o modelo\n",
    "joblib.dump(best_lr, '../models/best_lr.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Salvando parte dos dados com informações relevantes para o Web App\n",
    "Por fim, a parte dos dados que contém informações relevantes para o Web App\n",
    "será salva em um arquivo .db para ser consumido pelo app. Colunas referentes as\n",
    "notas dos candidatos serão removidas, pois serão fornecidas pelo usuário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicionando uma coluna extra na lista\n",
    "colunas_para_buscar.append('MOD_CONCORRENCIA')\n",
    "\n",
    "# Selecionando as colunas\n",
    "dados_to_save = dados_sisu_full[colunas_para_buscar]\n",
    "dados_to_save = dados_to_save.drop(['NOTA_L', 'NOTA_CH', 'NOTA_CN', 'NOTA_M', 'NOTA_R', 'NOTA_CANDIDATO'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando os dados no formato .db\n",
    "dados_to_save.to_sql('dados_to_web', 'sqlite:///../data/processed/dados_to_web.db', index=False, if_exists='replace')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
